{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "BN_NIPS21_Figures_3_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a2a7156bf8234d028db073003ccd9ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_83722ebd26984bbfb4fa6d675921b193",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7e94fd378fdb4a1fa05d91ba655cfc99",
              "IPY_MODEL_bda069fe05b24f75a0709af8baff7ed0"
            ]
          }
        },
        "83722ebd26984bbfb4fa6d675921b193": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e94fd378fdb4a1fa05d91ba655cfc99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fbeb6fba1eb144fcb5816d6d907f2aad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b70fa52b38a745859bdf7361c2695d20"
          }
        },
        "bda069fe05b24f75a0709af8baff7ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fcec701a07974b0c82b530ded44aaceb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [10:33&lt;00:00, 269158.70it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df9a07d33fce4f6e958c8ce4706d179a"
          }
        },
        "fbeb6fba1eb144fcb5816d6d907f2aad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b70fa52b38a745859bdf7361c2695d20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fcec701a07974b0c82b530ded44aaceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df9a07d33fce4f6e958c8ce4706d179a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMMoKz4iPbh2"
      },
      "source": [
        "This code generates **Figure 3 and 4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx46A8G8arzN"
      },
      "source": [
        "## Required Liberaries: \n",
        "#! pip3 install torch \n",
        "#! pip3 install torchvision\n",
        "# and GPUs"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_Ihh6BEOSxd"
      },
      "source": [
        "import numpy as np \n",
        "import torch \n",
        "import torchvision\n",
        "from matplotlib import pyplot as plt\n",
        "import math"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M745w4CofR-O"
      },
      "source": [
        "Loading cifar dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "a2a7156bf8234d028db073003ccd9ff2",
            "83722ebd26984bbfb4fa6d675921b193",
            "7e94fd378fdb4a1fa05d91ba655cfc99",
            "bda069fe05b24f75a0709af8baff7ed0",
            "fbeb6fba1eb144fcb5816d6d907f2aad",
            "b70fa52b38a745859bdf7361c2695d20",
            "fcec701a07974b0c82b530ded44aaceb",
            "df9a07d33fce4f6e958c8ce4706d179a"
          ]
        },
        "id": "GIB-Yw_jOSxk",
        "outputId": "00803f24-62ea-4252-d92d-d0e48cfb6f71"
      },
      "source": [
        "batch_size_train = 500\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.CIFAR10('./data/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "                             ])),\n",
        "  batch_size=batch_size_train, shuffle=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2a7156bf8234d028db073003ccd9ff2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Fcfh-eIRygo"
      },
      "source": [
        "# checking the hardware\n",
        "# !nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPu2ItfLOSxk"
      },
      "source": [
        "### tensor types, to run the code on CPU please update the types \n",
        "dtype = torch.cuda.FloatTensor # CPU -> torch.FloatTensor\n",
        "dtype_labels = torch.cuda.LongTensor # CPU -> torch.cuda.LongTensor"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJDe-AHUcg4d"
      },
      "source": [
        "Implementation of a multiLayer prectron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKy2O62cOSxl"
      },
      "source": [
        "class MLP(torch.nn.Module): \n",
        "    def __init__(self,layer_num,input_size,width,out_size,bias_on=False,act = None): # act is the activation function\n",
        "        super().__init__()\n",
        "        self.layer_num = layer_num\n",
        "        self.width = width\n",
        "        self.out_size = out_size\n",
        "        self.bias_on = bias_on\n",
        "        self.act = act\n",
        "        self.layers = torch.nn.ModuleList() # contains linear layers \n",
        "        self.layers.append(torch.nn.Linear(input_size,width,bias=bias_on))\n",
        "        for i in range(layer_num-2): \n",
        "              self.layers.append(torch.nn.Linear(width,width,bias=bias_on))\n",
        "        self.layers.append(torch.nn.Linear(width,out_size,bias=bias_on))\n",
        "        self.act = act\n",
        "    def forward(self,x): \n",
        "        out = x\n",
        "        index = 0\n",
        "        for lay in self.layers: # passing input through the layers \n",
        "            index = index +1 \n",
        "            if self.act is not None and index<self.layer_num: \n",
        "                out = self.act(lay(out))\n",
        "            else: \n",
        "                out = lay(out)\n",
        "        return out\n",
        "    def forward_minus(self,x): # skip the output layer\n",
        "        out = x\n",
        "        index = 0\n",
        "        for lay in self.layers:\n",
        "            index = index +1 \n",
        "            if self.act is not None and index<self.layer_num-1: \n",
        "                out = self.act(lay(out))\n",
        "        return out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKDWsppecn9c"
      },
      "source": [
        "\n",
        "MLP with batch normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3h_AkIXccnJT"
      },
      "source": [
        "class BNMLP(torch.nn.Module): \n",
        "    def __init__(self,layer_num,input_size,width,out_size,bias_on=False,act = None): # act is the activation function\n",
        "        super().__init__()\n",
        "        self.layer_num = layer_num\n",
        "        self.width = width\n",
        "        self.out_size = out_size\n",
        "        self.bias_on = bias_on\n",
        "        self.act = act\n",
        "        self.layers = torch.nn.ModuleList() # linear layers\n",
        "        self.layers.append(torch.nn.Linear(input_size,width,bias=bias_on))\n",
        "        for i in range(layer_num-2): \n",
        "              self.layers.append(torch.nn.Linear(width,width,bias=bias_on))\n",
        "        self.layers.append(torch.nn.Linear(width,out_size,bias=bias_on))\n",
        "        self.act = act\n",
        "        self.bns = torch.nn.ModuleList() # batch normalization layers\n",
        "        for i in range(layer_num-1): \n",
        "              self.bns.append(torch.nn.BatchNorm1d(num_features=width)) # for MLPs we use 1d batch normalization\n",
        "    def forward(self,x): \n",
        "        out = x\n",
        "        for i in range(self.layer_num-1):\n",
        "            if self.act is not None: \n",
        "                out = self.act(self.bns[i](self.layers[i](out)))\n",
        "            else: \n",
        "                out = self.bns[i](self.layers[i](out))\n",
        "       \n",
        "        out = self.layers[self.layer_num-1](out)\n",
        "        return out\n",
        "    "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "667Q9IWycugh"
      },
      "source": [
        "Here, we implement xavier's initialization of weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tOv3c55OSxl"
      },
      "source": [
        "layer_num = 50\n",
        "out_size =10 \n",
        "input_size = 3*32*32\n",
        "width = batch_size_train\n",
        "net = MLP(layer_num, input_size,width,out_size)\n",
        "net = net.cuda()\n",
        "def xavier_init(m): # xavier initialization \n",
        "    if isinstance(m, torch.nn.Linear):\n",
        "        torch.nn.init.xavier_uniform_(m.weight, gain=torch.nn.init.calculate_gain('relu'))\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.fill_(0)\n",
        "def kaiming_init(m):\n",
        "    if isinstance(m, torch.nn.Linear):\n",
        "        torch.nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.fill_(0)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5NpDsvbarBf"
      },
      "source": [
        "The following functions implements the iterative initialization. Let $H_\\ell \\in R^{d \\times n}$ denotes hidden representations in layer $\\ell$. we use SVD decompostion $H_\\ell = U_\\ell \\Sigma_\\ell V_\\ell^\\top$ to initialize weights in layer $\\ell$ as \n",
        "$$W_\\ell = \\frac{1}{\\| \\Sigma^{1/2} \\|_F } V'_\\ell \\Sigma_\\ell^{1/2} U_\\ell^\\top$$ \n",
        "where $V'_\\ell$ is a slice of $V_\\ell$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG4FevBCOSxm"
      },
      "source": [
        "def improved_init(net, width):\n",
        "   # picking a large mini batch of inputs\n",
        "    batch_size_train = 3*width\n",
        "    loader = torch.utils.data.DataLoader(\n",
        "      torchvision.datasets.CIFAR10('./data/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "                             ])),\n",
        "     batch_size=batch_size_train, shuffle=True)\n",
        "    examples = enumerate(loader)\n",
        "    batch_idx, (images, example_targets) = next(examples)\n",
        "    H0 = images.view(-1,3*32*32).type(dtype)\n",
        "   \n",
        "    H = H0\n",
        "    gamma = 0.1\n",
        "    layer_num = net.layer_num\n",
        "    # passing the input and compute the hidden representation and weights iteratively  \n",
        "    for i in range(layer_num-1):\n",
        "        if i>0: \n",
        "            Hdata = H.data\n",
        "            u,s, v = torch.svd(Hdata) # svd computation \n",
        "            wd = net.layers[i].weight.data.size(0)\n",
        "            w = u[0:wd,0:wd].mm(torch.diag(1/torch.pow(s[0:wd],1))).mm(v.t()[0:wd,:]) # weight initialization\n",
        "            net.layers[i].weight.data = w\n",
        "            net.layers[i].weight.data = w \n",
        "            net.layers[i].weight.data = net.layers[i].weight.data/torch.norm(net.layers[i](H)) # normalization factor\n",
        "        if net.act is not None:\n",
        "            H = net.act(net.layers[i](H))\n",
        "        else:\n",
        "            H = net.layers[i](H)\n",
        "   \n",
        "    return net\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqwVRELo544p"
      },
      "source": [
        "The following function computes the orthogonality gap, which measures how much singular values of output are deviated from a uniformaly distributed singualr values after normalization. Recall \n",
        "$$V(H_\\ell) = \\| H_\\ell^\\top H_\\ell/\\|H_\\ell\\|_F^2 - I_n/n \\|_F $$\n",
        "Which can be written alternative using singular values of $H_\\ell$ denoted by $\\sigma$ as \n",
        "$$V(H_\\ell) = \\| \\sigma^2 - I_n/n \\|_F$$ which measures how much singular values are deviated from a uniformly distributed singular values. In our experiments, we measure the gap by $\\|\\sigma -1/\\sqrt{n} \\|$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JJZoiWTue92"
      },
      "source": [
        "def compute_orthogonality_gap(net):\n",
        "  loader = torch.utils.data.DataLoader(\n",
        "      torchvision.datasets.CIFAR10('./data/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "                             ])),\n",
        "     batch_size=batch_size_train, shuffle=True)\n",
        "  avg_gap = 0\n",
        "  index = 0 \n",
        "  for x,y in loader: \n",
        "    index += 1\n",
        "    x = x.type(dtype)\n",
        "    y = y.type(dtype_labels)\n",
        "    out = net.forward(torch.flatten(x,1))\n",
        "    u1,s1,v1 = torch.svd(out.data)\n",
        "    s1 = s1/torch.norm(s1)\n",
        "    s2 = torch.tensor(np.ones(s1.size(0))/math.sqrt(s1.size(0))).type(dtype)\n",
        "    avg_gap += torch.norm(s1-s2)\n",
        "  avg_gap = avg_gap/index\n",
        "  print('average of the orthogonality gap is ',avg_gap)\n",
        "  return avg_gap"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmp297Vt8B4s"
      },
      "source": [
        "def train(net,train_loader,epochs_num = 10,stepsize=0.01):\n",
        "    loss_function = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(net.parameters(),lr=stepsize)\n",
        "    conv = []\n",
        "    gaps = []\n",
        "    itrs = []\n",
        "    for i in range(epochs_num):\n",
        "        current_loss = 0 \n",
        "        r_size = 0\n",
        "        for x,y in train_loader: \n",
        "            x = x.type(dtype)\n",
        "            y = y.type(dtype_labels)\n",
        "            r_size += x.size(0)\n",
        "            optimizer.zero_grad()\n",
        "            predy = net(torch.flatten(x,1))\n",
        "            loss = loss_function(predy,y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            current_loss += loss.item()*batch_size_train\n",
        "        if i % 5 == 0:\n",
        "          gaps.append(compute_orthogonality_gap(net))   \n",
        "          conv.append(current_loss/r_size)\n",
        "          itrs.append(i+1)\n",
        "          print(current_loss/r_size) \n",
        "    return conv,gaps,itrs"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLk-Gv2woS8S"
      },
      "source": [
        "# computing the decay in the orthogonality gap for the iterative initialization ## in figure 3.b \n",
        "ACTIVE = torch.nn.functional.relu\n",
        "convs =[] # convergence rate\n",
        "gaps = [] # orthogonality gap during training\n",
        "repeat = 5\n",
        "for i in range(repeat):\n",
        "  mynet = MLP(20, input_size,1000,out_size,act=torch.nn.functional.relu,bias_on = False)\n",
        "  mynet = mynet.cuda()\n",
        "  mynet.apply(xavier_init)\n",
        "  conv, gap,itrs = train(mynet,train_loader,epochs_num = 50)\n",
        "  convs.append(conv)\n",
        "  gaps.append(gap)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBptIV3EjdPN"
      },
      "source": [
        "The convergence for different initialization methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nF9PijG9iVY"
      },
      "source": [
        "# Figures 3.a, 4.a, and 4.b\n",
        "layers = [15,30,45,60,75]\n",
        "bias_on = False\n",
        "width = 800\n",
        "epochs = 30\n",
        "repeat = 4\n",
        "ACTIVE = torch.nn.functional.relu\n",
        "ouresults = np.zeros((len(layers),epochs,repeat))\n",
        "xavir_result = np.zeros((len(layers),epochs,repeat))\n",
        "for j in range(repeat):\n",
        "  for i in range(len(layers)): \n",
        "      layer_num = layers[i]\n",
        "      mynet = MLP(layer_num, input_size,width,out_size,act=ACTIVE,bias_on = bias_on)\n",
        "      mynet = mynet.cuda()\n",
        "      mynet.apply(xavier_init)\n",
        "      mynet = improved_init(mynet,width)\n",
        "      print(i,'our initialization -----')\n",
        "      res = train(mynet,train_loader,epochs_num = epochs)\n",
        "      ouresults[i,:,j] = res[0]\n",
        "      print(i,'xavier initialization----')\n",
        "      netx = MLP(layer_num, input_size,width,out_size,act=ACTIVE,bias_on = bias_on)\n",
        "      netx = netx.cuda()\n",
        "      netx = netx.apply(xavier_init)\n",
        "      result_xavier =  train(netx,train_loader,epochs_num = epochs)\n",
        "      xavir_result[i,:,j] =result_xavier[0]\n",
        "     "
      ],
      "execution_count": 2,
      "outputs": []
    }
  ]
}